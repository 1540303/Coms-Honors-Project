{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    ".. _tut_viz_evoked:\n",
    "\n",
    "# Visualize Evoked data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os.path as op\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we focus on plotting functions of :class:`mne.Evoked`.\n",
    "Here we read the evoked object from a file. Check out\n",
    ":ref:`tut_epoching_and_averaging` to get to this stage from raw data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_path = 'C:/Anaconda2/Lib/site-packages/examples/mne-testing-data-master'\n",
    "fname = op.join(data_path, 'MEG', 'sample', 'sample_audvis-ave.fif')\n",
    "evoked = mne.read_evokeds(fname, baseline=(None, 0), proj=True)\n",
    "print(evoked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that ``evoked`` is a list of evoked instances. You can read only one\n",
    "of the categories by passing the argument ``condition`` to\n",
    ":func:`mne.read_evokeds`. To make things more simple for this tutorial, we\n",
    "read each instance to a variable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evoked_l_aud = evoked[0]\n",
    "evoked_r_aud = evoked[1]\n",
    "evoked_l_vis = evoked[2]\n",
    "evoked_r_vis = evoked[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a simple one. We plot event related potentials / fields\n",
    "(ERP/ERF). The bad channels are not plotted by default. Here we explicitly\n",
    "set the exclude parameter to show the bad channels in red. All plotting\n",
    "functions of MNE-python return a handle to the figure instance. When we have\n",
    "the handle, we can customise the plots to our liking.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = evoked_l_aud.plot(exclude=())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All plotting functions of MNE-python returns a handle to the figure instance.\n",
    "When we have the handle, we can customise the plots to our liking. We can get\n",
    "rid of the empty space with a simple function call.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make it a bit fancier and only use MEG channels. Many of the\n",
    "MNE-functions include a ``picks`` parameter to include a selection of\n",
    "channels. ``picks`` is simply a list of channel indices that you can easily\n",
    "construct with :func:`mne.pick_types`. See also :func:`mne.pick_channels` and\n",
    ":func:`mne.pick_channels_regexp`.\n",
    "Using ``spatial_colors=True``, the individual channel lines are color coded\n",
    "to show the sensor positions - specifically, the x, y, and z locations of\n",
    "the sensors are transformed into R, G and B values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "picks = mne.pick_types(evoked_l_aud.info, meg=True, eeg=False, eog=False)\n",
    "evoked_l_aud.plot(spatial_colors=True, gfp=True, picks=picks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the legend on the left. The colors would suggest that there may be two\n",
    "separate sources for the signals. This wasn't obvious from the first figure.\n",
    "Try painting the slopes with left mouse button. It should open a new window\n",
    "with topomaps (scalp plots) of the average over the painted area. There is\n",
    "also a function for drawing topomaps separately.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evoked_l_aud.plot_topomap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default the topomaps are drawn from evenly spread out points of time over\n",
    "the evoked data. We can also define the times ourselves.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "times = np.arange(0.05, 0.151, 0.05)\n",
    "evoked_r_aud.plot_topomap(times=times, ch_type='mag')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can automatically select the peaks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evoked_r_aud.plot_topomap(times='peaks', ch_type='mag')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can take a look at the documentation of :func:`mne.Evoked.plot_topomap`\n",
    "or simply write ``evoked_r_aud.plot_topomap?`` in your python console to\n",
    "see the different parameters you can pass to this function. Most of the\n",
    "plotting functions also accept ``axes`` parameter. With that, you can\n",
    "customise your plots even further. First we shall create a set of matplotlib\n",
    "axes in a single figure and plot all of our evoked categories next to each\n",
    "other.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 5)\n",
    "evoked_l_aud.plot_topomap(times=0.1, axes=ax[0], show=False)\n",
    "evoked_r_aud.plot_topomap(times=0.1, axes=ax[1], show=False)\n",
    "evoked_l_vis.plot_topomap(times=0.1, axes=ax[2], show=False)\n",
    "evoked_r_vis.plot_topomap(times=0.1, axes=ax[3], show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we created five axes, but had only four categories. The fifth\n",
    "axes was used for drawing the colorbar. You must provide room for it when you\n",
    "create this kind of custom plots or turn the colorbar off with\n",
    "``colorbar=False``. That's what the warnings are trying to tell you. Also, we\n",
    "used ``show=False`` for the three first function calls. This prevents the\n",
    "showing of the figure prematurely. The behavior depends on the mode you are\n",
    "using for your python session. See http://matplotlib.org/users/shell.html for\n",
    "more information.\n",
    "\n",
    "We can combine the two kinds of plots in one figure using the ``plot_joint``\n",
    "method of Evoked objects. Called as-is (``evoked.plot_joint()``), this\n",
    "function should give a stylish and informative display of spatio-temporal\n",
    "dynamics. Also note the ``topomap_args`` and ``ts_args`` parameters of\n",
    ":func:`mne.Evoked.plot_joint`. You can pass key-value pairs as a python\n",
    "dictionary that gets passed as parameters to the topomaps\n",
    "(:func:`mne.Evoked.plot_topomap`) and time series (:func:`mne.Evoked.plot`)\n",
    "of the joint plot.\n",
    "For specific styling, use these ``topomap_args`` and ``ts_args``\n",
    "arguments. Here, topomaps at specific time points (70 and 105 msec) are\n",
    "shown, sensors are not plotted, and the Global Field Power is shown:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ts_args = dict(gfp=True)\n",
    "topomap_args = dict(sensors=False)\n",
    "evoked_r_aud.plot_joint(title='right auditory', times=[.07, .105],\n",
    "                        ts_args=ts_args, topomap_args=topomap_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the activations as images. The time runs along the x-axis\n",
    "and the channels along the y-axis. The amplitudes are color coded so that\n",
    "the amplitudes from negative to positive translates to shift from blue to\n",
    "red. White means zero amplitude. You can use the ``cmap`` parameter to define\n",
    "the color map yourself. The accepted values include all matplotlib colormaps.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evoked_r_aud.plot_image(picks=picks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we plot the sensor data as a topographical view. In the simple case\n",
    "we plot only left auditory responses, and then we plot them all in the same\n",
    "figure for comparison. Click on the individual plots to open them bigger.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "title = 'MNE sample data (condition : %s)'\n",
    "evoked_l_aud.plot_topo(title=title % evoked_l_aud.comment)\n",
    "colors = 'yellow', 'green', 'red', 'blue'\n",
    "mne.viz.plot_evoked_topo(evoked, color=colors,\n",
    "                         title=title % 'Left/Right Auditory/Visual')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing field lines in 3D\n",
    "-----------------------------\n",
    "\n",
    "We now compute the field maps to project MEG and EEG data to MEG helmet\n",
    "and scalp surface.\n",
    "\n",
    "To do this we'll need coregistration information. See\n",
    ":ref:`tut_forward` for more details.\n",
    "\n",
    "Here we just illustrate usage.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subjects_dir = data_path + '/subjects'\n",
    "trans_fname = data_path + '/MEG/sample/sample_audvis_raw-trans.fif'\n",
    "\n",
    "maps = mne.make_field_map(evoked_l_aud, trans=trans_fname, subject='sample',\n",
    "                          subjects_dir=subjects_dir, n_jobs=1)\n",
    "\n",
    "# explore several points in time\n",
    "field_map = evoked_l_aud.plot_field(maps, time=.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".. note::\n",
    "    If trans_fname is set to None then only MEG estimates can be visualized.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
